# 비지도학습과 K-평균 군집화

## 1. 비지도학습 (Unsupervised Learning) 개념

### 정의와 특징

**비지도학습(Unsupervised Learning)**은 정답(레이블)이 없는 데이터를 사용하여 데이터 내에 숨겨진 구조, 패턴, 관계 등을 스스로 학습하는 머신러닝 방식입니다.

### 지도학습과의 차이

| 지도학습 (Supervised Learning) | 비지도학습 (Unsupervised Learning) |
|--------------------------|----------------------------|
| 입력과 출력(레이블)이 모두 제공됨 | 입력만 제공되고 출력(레이블)은 제공되지 않음 |
| 예측이나 분류가 주요 목표 | 패턴 발견이나 데이터 구조화가 주요 목표 |
| 모델 성능을 정확히 평가 가능 | 모델 성능 평가가 상대적으로 어려움 |
| 예시: 분류(classification), 회귀(regression) | 예시: 군집화(clustering), 차원 축소(dimensionality reduction) |

### 비지도학습의 주요 목표

- **데이터 그룹화(군집화)**: 유사한 특성을 가진 데이터를 그룹으로 묶음
- **차원 축소**: 중요한 정보는 유지하면서 데이터의 복잡성 감소
- **이상치 탐지**: 일반적인 패턴에서 벗어난 데이터 식별
- **연관 규칙 학습**: 데이터 항목 간 관계 파악
- **잠재 구조 발견**: 데이터에 내재된 숨겨진 패턴 찾기

## 2. K-평균 군집 (K-Means Clustering)

### 개념과 원리

K-평균 군집화(K-Means Clustering)는 대표적인 비지도학습 기반 군집화 알고리즘으로, 주어진 데이터를 K개의 클러스터(군집)로 묶는 방법입니다. 각 클러스터는 **중심점(Centroid)**을 가지며, 데이터 포인트들은 가장 가까운 중심점에 속하게 됩니다.

### 목표

K-평균 군집화의 주요 목표는 다음과 같습니다:

- 각 클러스터 내 데이터 포인트들의 분산을 최소화
- 클러스터 간 차이는 최대화
- 수학적으로 표현하면, 각 데이터 포인트와 해당 클러스터 중심점 간의 거리 제곱 합을 최소화:

$$\min_{C} \sum_{k=1}^{K} \sum_{x \in C_k} \|x - \mu_k\|^2$$

여기서:
- $C_k$는 k번째 클러스터
- $\mu_k$는 k번째 클러스터의 중심점
- $x$는 데이터 포인트

## 3. K-평균 군집 알고리즘 순서

### 1. 데이터 준비
- 분석할 원본 데이터를 수집하고 전처리합니다.
- 필요한 경우 데이터 정규화나 표준화를 수행합니다.
- 결측치, 이상치 등을 처리합니다.

### 2. 클러스터 개수(K) 정하기
데이터를 몇 개의 그룹으로 나눌지 결정합니다.

**방법:**
- **사전 지식 활용**: 도메인 지식이나 분석 목적에 따라 K를 직접 설정
- **엘보우 방법(Elbow Method)**: K값을 변화시키며 오차 제곱합(SSE, Sum of Squared Errors)을 그래프로 나타내어, 급격히 감소하다가 완만해지는 '팔꿈치' 지점을 최적의 K로 선택
- **실루엣 분석(Silhouette Analysis)**: 클러스터 내부 응집도와 분리도를 평가하는 실루엣 점수가 최대가 되는 K를 선택

### 3. 초기 중심점(Centroid) 설정
K개의 클러스터 각각을 대표할 초기 중심점의 위치를 결정합니다.

**방법:**
- **Random 방법**: 데이터 공간 내에서 무작위로 K개의 점을 선택
  - **단점**: 초기 위치에 따라 결과가 달라지고, 최적이 아닐 수 있음
  
- **K-means++ 방법**: 중심점들이 서로 멀리 떨어져 있도록 초기화
  - **절차**:
    1. 데이터 포인트 중 하나를 무작위로 첫 번째 중심점으로 선택
    2. 나머지 데이터 포인트들에 대해, 이미 선택된 중심점들과의 거리(제곱 거리)를 계산
    3. 기존 중심점들로부터 거리가 먼 데이터 포인트가 다음 중심점으로 선택될 확률이 높도록 설정하여, K개가 될 때까지 반복
  - **장점**:
    - Random 방법보다 더 안정적이고 좋은 군집화 결과를 얻을 가능성이 높음
    - 알고리즘의 수렴 속도가 더 빠름

### 4. 데이터 포인트 할당 (Assignment)
모든 데이터 포인트를 현재 설정된 K개의 중심점들과 비교합니다.

- 각 데이터 포인트는 자신과 가장 가까운 중심점에 해당하는 클러스터에 할당
- 거리 계산은 주로 **유클리드 거리(Euclidean Distance)**를 사용:
  
  $$d(x, c) = \sqrt{\sum_{i=1}^{n} (x_i - c_i)^2}$$
  
  여기서 $x$는 데이터 포인트, $c$는 중심점, $n$은 차원 수

### 5. 중심점 업데이트 (Update)
할당된 결과를 바탕으로, 각 클러스터에 속한 데이터 포인트들의 **평균 위치(mean)**를 계산하여 새로운 중심점으로 설정합니다.

$$c_j = \frac{1}{|C_j|} \sum_{x \in C_j} x$$

여기서 $c_j$는 클러스터 $j$의 새로운 중심점, $|C_j|$는 클러스터 $j$에 속한 데이터 포인트의 수

### 6. 반복 (Iteration)
4단계(할당)와 5단계(업데이트)를 반복 수행합니다.

**종료 조건**:
- 중심점의 위치가 더 이상 변하지 않거나, 아주 작은 변화만 있을 때
- 사전에 정의한 최대 반복 횟수에 도달했을 때
- 클러스터 할당이 더 이상 변하지 않을 때

### 7. 최종 클러스터 설정 완료
반복이 종료된 시점의 클러스터 할당 결과가 최종 군집화 결과가 됩니다.

## 4. K-평균 군집화의 장단점

### 장점
- 간단하고 구현하기 쉬움
- 대규모 데이터에도 효율적으로 적용 가능
- 선형 시간 복잡도(O(n))로 빠른 수행 가능
- 클러스터의 특성을 이해하기 쉬움

### 단점
- 초기 중심점 설정에 따라 결과가 달라질 수 있음
- 최적의 K값을 미리 알아야 함
- 구형(spherical) 클러스터만 효과적으로 찾을 수 있음
- 이상치(outlier)에 민감함
- 밀도가 다른 클러스터를 구분하는 데 어려움이 있음

## 5. 활용 사례

K-평균 군집화는 다양한 분야에서 활용됩니다:

- **고객 세분화**: 유사한 구매 패턴이나 행동을 보이는 고객 그룹화
- **이미지 압축**: 색상 공간에서 유사한 색상들을 하나의 대표 색으로 군집화
- **이상 탐지**: 정상 패턴에서 벗어난 데이터 포인트 식별
- **추천 시스템**: 유사한 취향을 가진 사용자 그룹 파악
- **문서 클러스터링**: 유사한 주제를 다루는 문서들을 그룹화

## 핵심 요약

- **비지도학습**은 레이블 없는 데이터에서 패턴을 찾는 머신러닝 방법론입니다.
- **K-평균 군집화**는 데이터를 K개의 그룹으로 나누는 대표적인 비지도학습 알고리즘입니다.
- 알고리즘은 **초기 중심점 설정 → 데이터 할당 → 중심점 업데이트** 과정을 중심점이 안정화될 때까지 반복합니다.
- 초기 중심점 설정 방법(Random vs K-means++)과 클러스터 개수(K) 선택이 군집화 결과에 중요한 영향을 미칩니다.
- 데이터 포인트와 중심점 간의 거리는 주로 유클리드 거리를 사용합니다.
